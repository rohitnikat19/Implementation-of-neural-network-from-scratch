{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6mp3J_kz_6f",
        "outputId": "dcba1e4f-4b68-4203-bfd9-ec7d15ae26ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Loss: 0.05835612086789916\n",
            "Epoch 1000 - Loss: 0.009218750000000001\n",
            "Epoch 2000 - Loss: 0.009218749999999986\n",
            "Epoch 3000 - Loss: 0.009218749999999986\n",
            "Epoch 4000 - Loss: 0.009218749999999986\n",
            "Epoch 5000 - Loss: 0.009218749999999986\n",
            "Epoch 6000 - Loss: 0.009218749999999986\n",
            "Epoch 7000 - Loss: 0.009218749999999986\n",
            "Epoch 8000 - Loss: 0.009218749999999986\n",
            "Epoch 9000 - Loss: 0.009218749999999986\n",
            "\n",
            "Predictions after training:\n",
            "[[0.8375]\n",
            " [0.8375]\n",
            " [0.8375]\n",
            " [0.8375]]\n",
            "\n",
            "Enter custom inputs for prediction (e.g., 'temperature humidity'):\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sigmoid Activation Function\n",
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Sigmoid activation function.\n",
        "    It maps any input to a value between 0 and 1.\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of Sigmoid Activation Function\n",
        "def sigmoid_derivative(x):\n",
        "    \"\"\"\n",
        "    Derivative of the sigmoid function.\n",
        "    This is used during backpropagation to calculate the gradient.\n",
        "    \"\"\"\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Neural Network Class Definition\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        \"\"\"\n",
        "        Initialize the neural network with the given sizes for the\n",
        "        input, hidden, and output layers.\n",
        "        - input_size: Number of input features\n",
        "        - hidden_size: Number of neurons in the hidden layer\n",
        "        - output_size: Number of output neurons\n",
        "        \"\"\"\n",
        "        # Randomly initialize the weights and biases\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Weights and biases initialization with random values\n",
        "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)  # Weights from input to hidden layer\n",
        "        self.bias_hidden = np.random.randn(1, self.hidden_size)  # Bias for hidden layer\n",
        "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)  # Weights from hidden to output layer\n",
        "        self.bias_output = np.random.randn(1, self.output_size)  # Bias for output layer\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Perform the forward pass of the neural network.\n",
        "        Compute the activations for the input, hidden, and output\n",
        "        layers.\n",
        "        - X: Input data (features)\n",
        "        Returns the output of the network.\n",
        "        \"\"\"\n",
        "        self.input_layer = X  # Store the input data\n",
        "\n",
        "        # Calculate the input to the hidden layer and apply the activation function\n",
        "        self.hidden_layer_input = np.dot(self.input_layer, self.weights_input_hidden) + self.bias_hidden\n",
        "        self.hidden_layer_output = sigmoid(self.hidden_layer_input)\n",
        "\n",
        "        # Calculate the input to the output layer and apply the activation function\n",
        "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_hidden_output) + self.bias_output\n",
        "        self.output_layer_output = sigmoid(self.output_layer_input)\n",
        "\n",
        "        return self.output_layer_output\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        \"\"\"\n",
        "        Perform the backward pass of the neural network (backpropagation).\n",
        "        This step adjusts the weights based on the error in the output.\n",
        "        - X: Input data (features)\n",
        "        - y: True labels (targets)\n",
        "        - learning_rate: The rate at which the weights are adjusted\n",
        "        \"\"\"\n",
        "        # Compute the error in the output layer\n",
        "        error_output = y - self.output_layer_output\n",
        "\n",
        "        # Calculate the gradient (delta) for the output layer\n",
        "        output_layer_delta = error_output * sigmoid_derivative(self.output_layer_output)\n",
        "\n",
        "        # Compute the error in the hidden layer\n",
        "        error_hidden = output_layer_delta.dot(self.weights_hidden_output.T)\n",
        "\n",
        "        # Calculate the gradient (delta) for the hidden layer\n",
        "        hidden_layer_delta = error_hidden * sigmoid_derivative(self.hidden_layer_output)\n",
        "\n",
        "        # Update the weights and biases using the computed gradients\n",
        "        # Update weights from hidden to output layer\n",
        "        self.weights_hidden_output += self.hidden_layer_output.T.dot(output_layer_delta) * learning_rate\n",
        "\n",
        "        # Update bias for the output layer\n",
        "        self.bias_output += np.sum(output_layer_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "        # Update weights from input to hidden layer\n",
        "        self.weights_input_hidden += X.T.dot(hidden_layer_delta) * learning_rate\n",
        "\n",
        "        # Update bias for the hidden layer\n",
        "        self.bias_hidden += np.sum(hidden_layer_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    def train(self, X, y, epochs, learning_rate):\n",
        "        \"\"\"\n",
        "        Train the neural network on the provided data using the forward and backward passes.\n",
        "        - X: Input data (features)\n",
        "        - y: True labels (targets)\n",
        "        - epochs: Number of times to iterate through the entire dataset\n",
        "        - learning_rate: Rate at which the weights are adjusted\n",
        "        \"\"\"\n",
        "        for epoch in range(epochs):\n",
        "            # Perform a forward pass\n",
        "            self.forward(X)\n",
        "\n",
        "            # Perform a backward pass (backpropagation)\n",
        "            self.backward(X, y, learning_rate)\n",
        "\n",
        "            # Print loss (mean squared error) every 1000 epochs\n",
        "            if epoch % 1000 == 0:\n",
        "                loss = np.mean(np.square(y - self.output_layer_output))  # Mean squared error\n",
        "                print(f\"Epoch {epoch} - Loss: {loss}\")\n",
        "\n",
        "# Main Program\n",
        "if __name__ == \"__main__\":\n",
        "    # Example input data (real-valued features)\n",
        "    X = np.array([[23.5, 60.0], [25.0, 65.0], [20.0, 50.0], [30.0, 80.0]])  # e.g., [temperature, humidity]\n",
        "    y = np.array([[0.8], [0.9], [0.7], [0.95]])  # e.g., some target value (like performance or rating)\n",
        "\n",
        "    # Create an instance of the NeuralNetwork class with:\n",
        "    # 2 input neurons (temperature, humidity), 4 hidden neurons, and 1 output neuron (target)\n",
        "    nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1)\n",
        "\n",
        "    # Train the network with the custom dataset for 10,000 epochs and a learning rate of 0.1\n",
        "    nn.train(X, y, epochs=10000, learning_rate=0.1)\n",
        "\n",
        "    # After training, print the final predictions of the network\n",
        "    print(\"\\nPredictions after training:\")\n",
        "    print(nn.forward(X))  # Test the network on the training inputs\n",
        "\n",
        "    # User input for prediction:\n",
        "    print(\"\\nEnter custom inputs for prediction (e.g., 'temperature humidity'):\")\n",
        "\n",
        "    # Loop to allow the user to enter multiple sets of inputs\n",
        "    while True:\n",
        "        # Taking user input as two space-separated values\n",
        "        user_input = input(\"Enter input (e.g., '23.5 60.0') or type 'exit' to quit: \").strip()\n",
        "\n",
        "        # Check if the user wants to exit the loop\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        # Convert the input string to a numpy array (only if it's valid input)\n",
        "        try:\n",
        "            user_input_array = np.array([list(map(float, user_input.split()))])\n",
        "\n",
        "            # Check if the input length is correct (2 input features for temperature and humidity)\n",
        "            if user_input_array.shape[1] != 2:\n",
        "                print(\"Please enter exactly two values: 'temperature humidity'.\")\n",
        "                continue\n",
        "\n",
        "            # Perform prediction\n",
        "            prediction = nn.forward(user_input_array)\n",
        "            print(f\"Prediction for input {user_input}: {prediction[0][0]}\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter two numerical values (e.g., '23.5 60.0').\")\n",
        "\n"
      ]
    }
  ]
}